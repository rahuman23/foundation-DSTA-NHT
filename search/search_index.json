{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Getting Started","text":"<p>Welcome to DSO Foundation Training Labs.</p> <p>Info</p> <p>Estimated time to complete the labs is as follows:</p> <ul> <li>DIY Foundation - 60 minutes</li> <li>Prism Central - 30 minutes</li> </ul>"},{"location":"#whats-new","title":"What's New","text":"<ul> <li>Workshop uses for the following software versions:</li> <li>AOS 6.8.0.5</li> <li>Prism Central pc.2024.1.0.1</li> </ul>"},{"location":"#agenda","title":"Agenda","text":"<ul> <li>DIY Foundation</li> <li>Deploying Prism Central</li> </ul>"},{"location":"#initial-setup","title":"Initial Setup","text":"<ul> <li>Take note of the Passwords being used from you RX reservation details</li> <li>Log into your virtual desktops (connection info below)</li> <li>Login to Global Protect VPN if you have access</li> </ul>"},{"location":"#frame-vdi","title":"Frame VDI","text":"<p>Login to: https://console.nutanix.com/x/labs</p> <p>Please use the following username and password to login to the Frame VDI desktop.</p> Name Cluster Name Frame Account Frame Account Pwd 1 Giam Xiong Yao PHX-POC263 PHX-POC263-User01 ntnx/4DSTA 2 Goh Hao Wei PHX-POC263 PHX-POC263-User02 ntnx/4DSTA 3 Lim Xi Yang PHX-POC263 PHX-POC263-User03 ntnx/4DSTA 4 Ong Sheng Jian PHX-POC263 PHX-POC263-User04 ntnx/4DSTA 5 Seah Wei Hong PHX-POC204 PHX-POC204-User01 ntnx/4DSTA 6 Tay Yi Hsuen PHX-POC204 PHX-POC204-User02 ntnx/4DSTA 7 Tanya Elizabeth Khoo PHX-POC204 PHX-POC204-User03 ntnx/4DSTA 8 Soh Boon Yen PHX-POC204 PHX-POC204-User04 ntnx/4DSTA 9 Lim Jun Wei PHX-POC002 PHX-POC002-User01 ntnx/4DSTA 10 Kenneth Neoh Kim How PHX-POC002 PHX-POC002-User02 ntnx/4DSTA 11 Yee Jun Wei PHX-POC002 PHX-POC002-User03 ntnx/4DSTA 12 Yang Kai Ze PHX-POC002 PHX-POC002-User04 ntnx/4DSTA 13 Lim Ka Tiong PHX-POC007 PHX-POC007-User01 ntnx/4DSTA 14 Wong Wei En, Matthew PHX-POC007 PHX-POC007-User02 ntnx/4DSTA 15 Wong Chin Hao PHX-POC007 PHX-POC007-User03 ntnx/4DSTA 16 PHX-POC007 PHX-POC007-User04 ntnx/4DSTA 17 PHX-POC062 PHX-POC062-User01 ntnx/4DSTA 18 PHX-POC062 PHX-POC062-User02 ntnx/4DSTA 19 PHX-POC062 PHX-POC062-User03 ntnx/4DSTA 20 PHX-POC062 PHX-POC062-User04 ntnx/4DSTA"},{"location":"#environment-details","title":"Environment Details","text":"<p>Nutanix Workshops are intended to be run in the Nutanix Hosted POC environment. Your cluster will be provisioned with all necessary images,networks, and VMs required to complete the exercises.</p>"},{"location":"#networking","title":"Networking","text":"<p>As we are able to provide single node clusters in the HPOC environment, we need to describe each sort of cluster separately. The clusters are setup and configured differently.</p> <p>Throughout the Workshop there are multiple instances where you will need to substitute XYZ with the correct octet for your subnet, for example: | IP Address     |   Description | | 10.42.XYZ.XX |  Nutanix Cluster Virtual IP   | | 10.42.XYZ.XX  |  DC VM IP, NTNXLAB.local Domain Controller   |</p> <p>Each cluster is configured with 2 VLANs which can be used for VMs:</p> Network Name Address VLAN DHCP Scope Primary 10.42.XYZ.1/25 0 10.42.XYZ.50-10.42.XYZ.124 Secondary 10.42.XYZ.129/25 XYZ1 10.42.XYZ.132-10.42.XYZ.253 <p>1 Node Cluster HPOC</p> <p>For some workshops we are using Single Node Clusters (SNC). The reason for this is to allow more people to have a dedicated cluster but still have enough free clusters for the bigger workshops including those for customers.</p> <p>The network in the SNC config is using a /26 network. This splits the network address into four equal sizes that can be used for workshops. The below table describes the setup of the network in the four partitions. It provides essential information for the workshop with respect to the IP addresses and the services running at that IP address.</p> Name Cluster Name IPMI IP HOST IP CVM IP Frame Account Frame Account Frame Account Pwd Foundation VM Foundation VM IP Cluster Name Cluster Password Primary Network Name Primary VLAN Primary GW Secondary Subnet Secondary IP Range Secondary VLAN Secondary GW IPMI Username IPMI Password DNS NTP Prism Cental IP Cluster IP DSIP 1 Giam Xiong Yao PHX-POC263 10.38.35.34 10.38.35.25 10.38.35.29 PHX-POC263-User01 ntnx/4DSTA ntnx/4DSTA FOVM_001 10.42.36.78 PHX-POC263-A ntnx/4DSTA 10.38.35.0/25 0 10.38.35.1 10.38.35.128/25 10.38.35.132-254 47 10.38.35.129 ADMIN ADMIN 10.42.194.10 0.POOL.NTP.ORG 10.38.35.45 10.38.35.50 10.38.35.55 2 Goh Hao Wei PHX-POC263 10.38.35.35 10.38.35.26 10.38.35.30 PHX-POC263-User02 ntnx/4DSTA ntnx/4DSTA FOVM_002 10.42.36.77 PHX-POC263-B ntnx/4DSTA 10.38.35.0/25 0 10.38.35.1 10.38.35.128/25 10.38.35.132-254 47 10.38.35.129 ADMIN ADMIN 10.42.194.10 0.POOL.NTP.ORG 10.38.35.46 10.38.35.51 10.38.35.56 3 Lim Xi Yang PHX-POC263 10.38.35.36 10.38.35.27 10.38.35.31 PHX-POC263-User03 ntnx/4DSTA ntnx/4DSTA FOVM_003 10.42.36.76 PHX-POC263-C ntnx/4DSTA 10.38.35.0/25 0 10.38.35.1 10.38.35.128/25 10.38.35.132-254 47 10.38.35.129 ADMIN ADMIN 10.42.194.10 0.POOL.NTP.ORG 10.38.35.47 10.38.35.52 10.38.35.57 4 Ong Sheng Jian PHX-POC263 10.38.35.37 10.38.35.28 10.38.35.32 PHX-POC263-User04 ntnx/4DSTA ntnx/4DSTA FOVM_004 10.42.36.71 PHX-POC263-D ntnx/4DSTA 10.38.35.0/25 0 10.38.35.1 10.38.35.128/25 10.38.35.132-254 47 10.38.35.129 ADMIN ADMIN 10.42.194.10 0.POOL.NTP.ORG 10.38.35.48 10.38.35.53 10.38.35.58 5 Seah Wei Hong PHX-POC204 10.38.204.33 10.38.204.25 10.38.204.29 PHX-POC204-User01 ntnx/4DSTA ntnx/4DSTA FOVM_005 10.42.36.75 PHX-POC204-A ntnx/4DSTA 10.38.204.0/25 0 10.38.204.1 10.38.204.128/25 10.38.204.132-254 2043 10.38.204.129 ADMIN ADMIN 10.42.194.10 0.POOL.NTP.ORG 10.38.204.45 10.38.204.50 10.38.204.55 6 Tay Yi Hsuen PHX-POC204 10.38.204.34 10.38.204.26 10.38.204.30 PHX-POC204-User02 ntnx/4DSTA ntnx/4DSTA FOVM_006 10.42.36.72 PHX-POC204-B ntnx/4DSTA 10.38.204.0/25 0 10.38.204.1 10.38.204.128/25 10.38.204.132-254 2043 10.38.204.129 ADMIN ADMIN 10.42.194.10 0.POOL.NTP.ORG 10.38.204.46 10.38.204.51 10.38.204.56 7 Tanya Elizabeth Khoo PHX-POC204 10.38.204.35 10.38.204.27 10.38.204.31 PHX-POC204-User03 ntnx/4DSTA ntnx/4DSTA FOVM_007 10.42.36.74 PHX-POC204-C ntnx/4DSTA 10.38.204.0/25 0 10.38.204.1 10.38.204.128/25 10.38.204.132-254 2043 10.38.204.129 ADMIN ADMIN 10.42.194.10 0.POOL.NTP.ORG 10.38.204.47 10.38.204.52 10.38.204.57 8 Soh Boon Yen PHX-POC204 10.38.204.36 10.38.204.28 10.38.204.32 PHX-POC204-User04 ntnx/4DSTA ntnx/4DSTA FOVM_008 10.42.36.56 PHX-POC204-D ntnx/4DSTA 10.38.204.0/25 0 10.38.204.1 10.38.204.128/25 10.38.204.132-254 2043 10.38.204.129 ADMIN ADMIN 10.42.194.10 0.POOL.NTP.ORG 10.38.204.48 10.38.204.53 10.38.204.58 9 Lim Jun Wei PHX-POC002 10.42.2.33 10.42.2.25 10.42.2.29 PHX-POC002-User01 ntnx/4DSTA ntnx/4DSTA FOVM_009 10.42.36.59 PHX-POC002-A ntnx/4DSTA 10.42.2.0/25 0 10.42.2.1 10.42.2.128/25 10.42.2.132-254 21 10.42.2.129 ADMIN ADMIN 10.42.194.10 0.POOL.NTP.ORG 10.42.2.45 10.42.2.50 10.42.2.55 10 Kenneth Neoh Kim How PHX-POC002 10.42.2.34 10.42.2.26 10.42.2.30 PHX-POC002-User02 ntnx/4DSTA ntnx/4DSTA FOVM_010 10.42.36.61 PHX-POC002-B ntnx/4DSTA 10.42.2.0/25 0 10.42.2.1 10.42.2.128/25 10.42.2.132-254 21 10.42.2.129 ADMIN ADMIN 10.42.194.10 0.POOL.NTP.ORG 10.42.2.46 10.42.2.51 10.42.2.56 11 Yee Jun Wei PHX-POC002 10.42.2.35 10.42.2.27 10.42.2.31 PHX-POC002-User03 ntnx/4DSTA ntnx/4DSTA FOVM_011 10.42.36.54 PHX-POC002-C ntnx/4DSTA 10.42.2.0/25 0 10.42.2.1 10.42.2.128/25 10.42.2.132-254 21 10.42.2.129 ADMIN ADMIN 10.42.194.10 0.POOL.NTP.ORG 10.42.2.47 10.42.2.52 10.42.2.57 12 Yang Kai Ze PHX-POC002 10.42.2.36 10.42.2.28 10.42.2.32 PHX-POC002-User04 ntnx/4DSTA ntnx/4DSTA FOVM_012 10.42.36.64 PHX-POC002-D ntnx/4DSTA 10.42.2.0/25 0 10.42.2.1 10.42.2.128/25 10.42.2.132-254 21 10.42.2.129 ADMIN ADMIN 10.42.194.10 0.POOL.NTP.ORG 10.42.2.48 10.42.2.53 10.42.2.58 13 Lim Ka Tiong PHX-POC007 10.42.7.33 10.42.7.25 10.42.7.29 PHX-POC007-User01 ntnx/4DSTA ntnx/4DSTA FOVM_013 10.42.36.63 PHX-POC007-A ntnx/4DSTA 10.42.7.0/25 0 10.42.7.1 10.42.7.128/25 10.42.7.132-254 71 10.42.7.129 ADMIN ADMIN 10.42.194.10 0.POOL.NTP.ORG 10.42.7.45 10.42.7.50 10.42.7.55 14 Wong Wei En, Matthew PHX-POC007 10.42.7.34 10.42.7.26 10.42.7.30 PHX-POC007-User02 ntnx/4DSTA ntnx/4DSTA FOVM_014 10.42.36.66 PHX-POC007-B ntnx/4DSTA 10.42.7.0/25 0 10.42.7.1 10.42.7.128/25 10.42.7.132-254 71 10.42.7.129 ADMIN ADMIN 10.42.194.10 0.POOL.NTP.ORG 10.42.7.46 10.42.7.51 10.42.7.56 15 Wong Chin Hao PHX-POC007 10.42.7.35 10.42.7.27 10.42.7.31 PHX-POC007-User03 ntnx/4DSTA ntnx/4DSTA FOVM_015 10.42.36.65 PHX-POC007-C ntnx/4DSTA 10.42.7.0/25 0 10.42.7.1 10.42.7.128/25 10.42.7.132-254 71 10.42.7.129 ADMIN ADMIN 10.42.194.10 0.POOL.NTP.ORG 10.42.7.47 10.42.7.52 10.42.7.57 16 PHX-POC007 10.42.7.36 10.42.7.28 10.42.7.32 PHX-POC007-User04 ntnx/4DSTA ntnx/4DSTA FOVM_016 10.42.36.67 PHX-POC007-D ntnx/4DSTA 10.42.7.0/25 0 10.42.7.1 10.42.7.128/25 10.42.7.132-254 71 10.42.7.129 ADMIN ADMIN 10.42.194.10 0.POOL.NTP.ORG 10.42.7.48 10.42.7.53 10.42.7.58 17 PHX-POC062 10.42.62.33 10.42.62.25 10.42.62.29 PHX-POC062-User01 ntnx/4DSTA ntnx/4DSTA FOVM_017 10.42.36.69 PHX-POC062-A ntnx/4DSTA 10.42.62.0/25 0 10.42.62.1 10.42.62.128/25 10.42.62.132-254 621 10.42.62.129 ADMIN ADMIN 10.42.194.10 0.POOL.NTP.ORG 10.42.62.45 10.42.62.50 10.42.62.55 18 PHX-POC062 10.42.62.34 10.42.62.26 10.42.62.30 PHX-POC062-User02 ntnx/4DSTA ntnx/4DSTA FOVM_018 10.42.36.70 PHX-POC062-B ntnx/4DSTA 10.42.62.0/25 0 10.42.62.1 10.42.62.0/25 10.42.62.132-254 621 10.42.62.129 ADMIN ADMIN 10.42.194.10 0.POOL.NTP.ORG 10.42.62.46 10.42.62.51 10.42.62.56 19 PHX-POC062 10.42.62.35 10.42.62.27 10.42.62.31 PHX-POC062-User03 ntnx/4DSTA ntnx/4DSTA FOVM_019 10.42.36.55 PHX-POC062-C ntnx/4DSTA 10.42.62.0/25 0 10.42.62.1 10.42.62.0/25 10.42.62.132-254 621 10.42.62.129 ADMIN ADMIN 10.42.194.10 0.POOL.NTP.ORG 10.42.62.47 10.42.62.52 10.42.62.57 20 PHX-POC062 10.42.62.36 10.42.62.28 10.42.62.32 PHX-POC062-User04 ntnx/4DSTA ntnx/4DSTA FOVM_020 10.42.36.68 PHX-POC062-D ntnx/4DSTA 10.42.62.0/25 0 10.42.62.1 10.42.62.0/25 10.42.62.132-254 621 10.42.62.129 ADMIN ADMIN 10.42.194.10 0.POOL.NTP.ORG 10.42.62.48 10.42.62.53 10.42.62.58"},{"location":"#credentials","title":"Credentials","text":"<p>Note</p> <p>The Cluster Password is unique to each cluster and will be provided by the leader of the Workshop.</p> Credential Username Password Prism Element admin ntnx/4DSTA Prism Central admin ntnx/4DSTA Controller VM nutanix ntnx/4DSTA Prism Central VM nutanix ntnx/4DSTA <p>Each cluster has a dedicated domain controller VM, DC, responsible for providing AD services for the NTNXLAB.local domain. The domain is populated with the following Users and Groups:</p> Group Username(s) Password Administrators Administrator nutanix/4u SSP Admins adminuser01-adminuser25 nutanix/4u SSP Developers devuser01-devuser25 nutanix/4u SSP Consumers consumer01-consumer25 nutanix/4u SSP Operators operator01-operator25 nutanix/4u SSP Custom custom01-custom25 nutanix/4u Bootcamp Users user01-user25 nutanix/4u"},{"location":"#access-instructions","title":"Access Instructions","text":"<p>The Nutanix Hosted POC environment can be accessed a number of different ways:</p>"},{"location":"#lab-access-user-credentials","title":"Lab Access User Credentials","text":"<p>PHX Based Clusters:</p> <ul> <li>Username: PHX-POCxxx-User01 (up to PHX-POCxxx-User20),</li> <li>Password: Provided by Instructor</li> </ul> <p>RTP Based Clusters:</p> <ul> <li>Username: RTP-POCxxx-User01 (up to RTP-POCxxx-User20),</li> <li>Password: Provided by Instructor</li> </ul>"},{"location":"#nutanix-version-info","title":"Nutanix Version Info","text":"<ul> <li>AOS 6.8.0.5</li> <li>Prism Central pc.2024.1.0.1</li> </ul>"},{"location":"#access-to-lab-info","title":"Access to lab info","text":"<p>Find information about labs here</p>"},{"location":"diyfoundation/diyfoundation/","title":"Overview","text":"<p>Info</p> <pre><code>Estimated time to complete: **60 Minutes**\n</code></pre> <p>Foundation is used to automate the installation of the hypervisor and Controller VM on one or more nodes. In this exercise you will practice imaging a physical cluster with Foundation. In order to keep the lab self-contained, you will create a single node cluster on which you will deploy your Foundation VM. That Foundation instance will be used to image and create a cluster from the remaining 3 nodes in the Block.</p> <p>Caution</p> <pre><code>  In following steps, you should replace xx part of the IP octet with your assigned cluster ID\n</code></pre>"},{"location":"diyfoundation/diyfoundation/#please-find-the-below-table-for-your-foundation-vm-ip","title":"Please find the below table for your Foundation VM IP","text":"<p>Please open up a browser and enter the IP address of the foundation IP address. This will bring you foundation VM page. Step 1 has been done for you to save time of uploading the image. Please proceed with Step 3!</p> Name Foundation VM Foundation VM IP 1 Giam Xiong Yao FOVM_001 10.42.36.78 2 Goh Hao Wei FOVM_002 10.42.36.77 3 Lim Xi Yang FOVM_003 10.42.36.76 4 Ong Sheng Jian FOVM_004 10.42.36.71 5 Seah Wei Hong FOVM_005 10.42.36.75 6 Tay Yi Hsuen FOVM_006 10.42.36.72 7 Tanya Elizabeth Khoo FOVM_007 10.42.36.74 8 Soh Boon Yen FOVM_008 10.42.36.56 9 Lim Jun Wei FOVM_009 10.42.36.59 10 Kenneth Neoh Kim How FOVM_010 10.42.36.61 11 Yee Jun Wei FOVM_011 10.42.36.54 12 Yang Kai Ze FOVM_012 10.42.36.64 13 Lim Ka Tiong FOVM_013 10.42.36.63 14 Wong Wei En, Matthew FOVM_014 10.42.36.66 15 Wong Chin Hao FOVM_015 10.42.36.65 16 FOVM_016 10.42.36.67 17 FOVM_017 10.42.36.69 18 FOVM_018 10.42.36.70 19 FOVM_019 10.42.36.55 20 FOVM_020 10.42.36.68"},{"location":"diyfoundation/diyfoundation/#foundation-node-abc-cluster","title":"Foundation Node ABC cluster","text":"<p>Note</p> <p>We will do this section of the lab from your desktop (Windows or Mac) computer. This is the fastest way as remote consoles will be slow.</p> <p>By default, Foundation does not have any AOS or hypervisor images. You can download your desired AOS package from the Nutanix Portal.</p> <ol> <li> <p>From you desktop computer, open Google Chrome browser and navigate to Foundation VM's IP</p> </li> <li> <p>Access Foundation UI via any browser at <code>http://&lt;Foundation VM IP&gt;</code></p> </li> <li> <p>Fill the following fields:</p> <ul> <li>Select your hardware platform: Autodetect</li> <li>Netmask of Every Host and CVM - 255.255.255.128</li> <li>Gateway of Every Host and CVM - 10.42.xx.1</li> <li>Gateway of Every IPMI - 10.42.xx.1</li> <li>Netmask of Every IPMI - 255.255.255.128</li> <li>Under Double-check this installer's networking step</li> <li>Skip this Validation - selected</li> </ul> <p></p> </li> <li> <p>In new foundation page, Tools menu choose Remove Unselected Rows to clear all auto discovered nodes</p> <p></p> </li> <li> <p>Click Add nodes manually</p> <p></p> </li> <li> <p>Fill in block information, fill in the following information:</p> <ul> <li>Number of blocks - 1</li> <li>Number of nodes - 1</li> <li>How should these nodes be reached? - choose I will provide the IPMI's MACs</li> </ul> </li> <li> <p>Click Add</p> <p></p> <p>Tip</p> <p>Foundation will automatically discover any hosts in the same IPv6 Link Local broadcast domain that is not already part of a cluster.</p> <p>When transferring POC assets in the field, it's not uncommon to receive a cluster that wasn't properly destroyed at the conclusion of the previous POC. In that case, the nodes are already part of existing clusters and will not be discovered.</p> <p>In this lab, we choose manually specify the MAC address instead in order to practice as the real world.</p> <p>Info</p> <p>There are at least 2 methods to get MAC address remotely.</p> <p>Method.1: Identify IPMI MAC Address (BMC MAC address) of Nodes (A, B, and C) by accessing IPMI IP in a browser for each node</p> <p>Method.2 Identify IPMI MAC Address of Nodes (A, B, C) by logging to the AHV hosts with User: root, Password: default for each node and using the following commands:</p> <pre><code>ssh -l root &lt;IP address of Host/Hypervisor&gt;\n</code></pre> <p><pre><code>ipmitool lan print | grep \"MAC Address\"\n</code></pre> <pre><code># output here\nMAC Address             : 0c:c4:7a:3c:c9:ad\n# repeat for nodes B and C for unique IPMI MAC addresses\n</code></pre></p> </li> <li> <p>Access Node A IPMI through IP 10.42.xx.33 with ADMIN/ADMIN</p> <p></p> <p></p> </li> <li> <p>Record your NODE A/B/C BMC MAC address (in above example , it is ac:1f:6b:1e:95:eb )</p> <p>Doing the same with your other 2 nodes B/C, access Node B and C IPMI through IP 10.42.xx.34/35 with ADMIN/ADMIN, record all 3 BMC MAC addresses.</p> </li> <li> <p>Click Tools and select Range Autofill from the drop down list</p> </li> <li> <p>Depending on which cluster you are using, Rahuman has being a nice guy has provided you with the range of IP address to fill in for all the nodes. Look for your cluster IPMI, HOST and CVM IP and fill up on your foundation page:</p> <ul> <li>IPMI IP - 10.42 or 38.xx.33,34,35,36</li> <li>Hypervisor IP - 10.42 or 38.xx.25,26,27,28</li> <li>CVM IP - 10.42 or 38.xx.29,30,31,32</li> <li>HOSTNAME OF HOST -- POCxx-A</li> </ul> Name Cluster Name IPMI IP HOST IP CVM IP Cluster Name Cluster IP DSIP 1 Giam Xiong Yao PHX-POC263 10.38.35.34 10.38.35.25 10.38.35.29 PHX-POC263-A 10.38.35.50 10.38.35.55 2 Goh Hao Wei PHX-POC263 10.38.35.35 10.38.35.26 10.38.35.30 PHX-POC263-B 10.38.35.51 10.38.35.56 3 Lim Xi Yang PHX-POC263 10.38.35.36 10.38.35.27 10.38.35.31 PHX-POC263-C 10.38.35.52 10.38.35.57 4 Ong Sheng Jian PHX-POC263 10.38.35.37 10.38.35.28 10.38.35.32 PHX-POC263-D 10.38.35.53 10.38.35.58 5 Seah Wei Hong PHX-POC204 10.38.204.33 10.38.204.25 10.38.204.29 PHX-POC204-A 10.38.204.50 10.38.204.55 6 Tay Yi Hsuen PHX-POC204 10.38.204.34 10.38.204.26 10.38.204.30 PHX-POC204-B 10.38.204.51 10.38.204.56 7 Tanya Elizabeth Khoo PHX-POC204 10.38.204.35 10.38.204.27 10.38.204.31 PHX-POC204-C 10.38.204.52 10.38.204.57 8 Soh Boon Yen PHX-POC204 10.38.204.36 10.38.204.28 10.38.204.32 PHX-POC204-D 10.38.204.53 10.38.204.58 9 Lim Jun Wei PHX-POC002 10.42.2.33 10.42.2.25 10.42.2.29 PHX-POC002-A 10.42.2.50 10.42.2.55 10 Kenneth Neoh Kim How PHX-POC002 10.42.2.34 10.42.2.26 10.42.2.30 PHX-POC002-B 10.42.2.51 10.42.2.56 11 Yee Jun Wei PHX-POC002 10.42.2.35 10.42.2.27 10.42.2.31 PHX-POC002-C 10.42.2.52 10.42.2.57 12 Yang Kai Ze PHX-POC002 10.42.2.36 10.42.2.28 10.42.2.32 PHX-POC002-D 10.42.2.53 10.42.2.58 13 Lim Ka Tiong PHX-POC007 10.42.7.33 10.42.7.25 10.42.7.29 PHX-POC007-A 10.42.7.50 10.42.7.55 14 Wong Wei En, Matthew PHX-POC007 10.42.7.34 10.42.7.26 10.42.7.30 PHX-POC007-B 10.42.7.51 10.42.7.56 15 Wong Chin Hao PHX-POC007 10.42.7.35 10.42.7.27 10.42.7.31 PHX-POC007-C 10.42.7.52 10.42.7.57 16 PHX-POC007 10.42.7.36 10.42.7.28 10.42.7.32 PHX-POC007-D 10.42.7.53 10.42.7.58 17 PHX-POC062 10.42.62.33 10.42.62.25 10.42.62.29 PHX-POC062-A 10.42.62.50 10.42.62.55 18 PHX-POC062 10.42.62.34 10.42.62.26 10.42.62.30 PHX-POC062-B 10.42.62.51 10.42.62.56 19 PHX-POC062 10.42.62.35 10.42.62.27 10.42.62.31 PHX-POC062-C 10.42.62.52 10.42.62.57 20 PHX-POC062 10.42.62.36 10.42.62.28 10.42.62.32 PHX-POC062-D 10.42.62.53 10.42.62.58 <p></p> </li> <li> <p>Click Next</p> </li> <li> <p>In the Cluster page, fill the following details:</p> <ul> <li>Cluster Name - POCxx-ABC</li> <li>Timezone of Every Hypervisor and CVM - America/Phoenix</li> <li>Cluster Redundancy Factor - RF2</li> <li>Cluster Virtual IP - 10.42.xx.xx</li> <li>NTP Servers of Every Hypervisor and CVM - 0.pool.ntp.org,1.pool.ntp.org,2.pool.ntp.org,3.pool.ntp.org</li> <li>DNS Servers of Every Hypervisor and CVM -  <li>vRAM Allocation for Every CVM, in Gigabytes - 32</li> <p></p> <li> <p>Click Next</p> <ul> <li>Select an AOS installer - Select your uploaded (simply use whatever that was uploaded for you)     nutanix_installer_package-release-.tar.gz* file</li> <li>The AOS Should be 6.8, screenshot file is for reference </li> <li>Arguments to the AOS Installer (Optional) - leave blank</li> </ul> <p></p> </li> <li> <p>Click Next</p> </li> <li> <p>Fill out the following fields and click Next:</p> <ul> <li>Select a hypervisor installer - AHV, AHV installer bundled inside the AOS installer</li> <li>Select AHV-DVD-x86_64-el8.nutanix.20230302.100187.iso - from AOS 6.8 onwards, hypervisor file needs to be uploaded to Foundation VM.</li> </ul> <p></p> <p>Tip</p> <p>Every AOS release contains a version of AHV bundle with that release.</p> </li> <li> <p>Click Next</p> </li> <li> <p>Enter the existing IPMI credentials as ADMIN and ADMIN for all nodes. Note that this will be different in the field.</p> <p></p> </li> <li> <p>Click Start</p> </li> <li> <p>Confirm that the installer will be active by clicking on Won't Sleep</p> <p></p> </li> <li> <p>In the Warning of Data Loss Possibility window, click on Ignore and Re-image</p> <p></p> <p>Foundation will run a couple of tests to make sure all the configuration details you have provided are correct and then direct you the installation progress page.</p> </li> <li> <p>Click the Log link to view the realtime log output from your node.</p> <p></p> <p>When all CVMs are ready, Foundation initiates the cluster creation process.</p> </li> <li> <p>Monitor the foundation process until completion</p> <p></p> </li> <li> <p>Once Foundation finishes successully, either click on Click here</p> <ul> <li>IMPORTANT: Foundation will not be able to successfully create cluster for this version of AOS. We will need to SSH into CVM IP using Putty.</li> <li>Username - nutanix</li> <li>Change the Password - nutanix/4u</li> <li>run the following command to create a 1 node cluster</li> <li><code>cluster --cluster_name=PHX-POC263-A --cluster_external_ip=10.38.xx.xx --ntp_servers=0.POOL.NTP.ORG --dns_servers=10.42.194.10 --svm_ips=10.38.xx.xx --cluster_function_list=one_node_cluster create</code></li> <li>Please refer to table for External IP, CVM IP and Cluster Name</li> </ul> Name HOST IP CVM IP Cluster Name Cluster IP DSIP 1 Giam Xiong Yao 10.38.35.25 10.38.35.29 PHX-POC263-A 10.38.35.50 10.38.35.55 2 Goh Hao Wei 10.38.35.26 10.38.35.30 PHX-POC263-B 10.38.35.51 10.38.35.56 3 Lim Xi Yang 10.38.35.27 10.38.35.31 PHX-POC263-C 10.38.35.52 10.38.35.57 4 Ong Sheng Jian 10.38.35.28 10.38.35.32 PHX-POC263-D 10.38.35.53 10.38.35.58 5 Seah Wei Hong 10.38.204.25 10.38.204.29 PHX-POC204-A 10.38.204.50 10.38.204.55 6 Tay Yi Hsuen 10.38.204.26 10.38.204.30 PHX-POC204-B 10.38.204.51 10.38.204.56 7 Tanya Elizabeth Khoo 10.38.204.27 10.38.204.31 PHX-POC204-C 10.38.204.52 10.38.204.57 8 Soh Boon Yen 10.38.204.28 10.38.204.32 PHX-POC204-D 10.38.204.53 10.38.204.58 9 Lim Jun Wei 10.42.2.25 10.42.2.29 PHX-POC002-A 10.42.2.50 10.42.2.55 10 Kenneth Neoh Kim How 10.42.2.26 10.42.2.30 PHX-POC002-B 10.42.2.51 10.42.2.56 11 Yee Jun Wei 10.42.2.27 10.42.2.31 PHX-POC002-C 10.42.2.52 10.42.2.57 12 Yang Kai Ze 10.42.2.28 10.42.2.32 PHX-POC002-D 10.42.2.53 10.42.2.58 13 Lim Ka Tiong 10.42.7.25 10.42.7.29 PHX-POC007-A 10.42.7.50 10.42.7.55 14 Wong Wei En, Matthew 10.42.7.26 10.42.7.30 PHX-POC007-B 10.42.7.51 10.42.7.56 15 Wong Chin Hao 10.42.7.27 10.42.7.31 PHX-POC007-C 10.42.7.52 10.42.7.57 16 10.42.7.28 10.42.7.32 PHX-POC007-D 10.42.7.53 10.42.7.58 17 10.42.62.25 10.42.62.29 PHX-POC062-A 10.42.62.50 10.42.62.55 18 10.42.62.26 10.42.62.30 PHX-POC062-B 10.42.62.51 10.42.62.56 19 10.42.62.27 10.42.62.31 PHX-POC062-C 10.42.62.52 10.42.62.57 20 10.42.62.28 10.42.62.32 PHX-POC062-D 10.42.62.53 10.42.62.58 <p>Once cluster creation completed, open <code>https://&lt;Cluster Virtual IP&gt;:9440</code> (10.42.xx.xx)in your browser</p> </li> <li> <p>Log in with the following credentials:</p> <ul> <li>Username - admin</li> <li>Change the Password - use the same password in RX</li> </ul> </li> <li> <p>Once the password is changed, you can login to Prism Element</p> <p></p> </li>"},{"location":"diyfoundation/diyfoundation/#takeaways","title":"Takeaways","text":""},{"location":"diyfoundation/diyfoundation/#-you-have-successfully-prepared-your-environment-in-a-single-operation-called-foundation","title":"- You have successfully prepared your environment in a single operation called Foundation:","text":"<ul> <li>Installed Hypervisor (AHV) - This can also be ESXi or Hyper-V</li> <li>Installed CVM (AOS)<ul> <li>Distributed File System (Data Plane)</li> <li>Prism Element (Control Plane)</li> </ul> </li> </ul>"},{"location":"diyfoundation/diyfoundation/#reset-ui-login-password","title":"Reset UI Login password","text":"<ul> <li>Login to CVM via ssh (username: nutanix password: nutanix/4u)</li> <li>execute the following commands</li> <li>ncli user reset-password user-name=\"admin\" password=ntnx/4DSTA</li> </ul> <p>Now we will proceed to install Prism Central(PC).  PC can manage several Prism Elements akin to cloud managers provided by public cloud providers.</p>"},{"location":"pcdeploy/pcdeploy/","title":"Overview","text":"<p>Info</p> <p>Estimated time to complete: 30 Minutes</p> <p>This lab will introduce Prism Central's(PC) One-Click deploy process</p>"},{"location":"pcdeploy/pcdeploy/#create-primary-and-secondary-networks","title":"Create Primary and Secondary networks","text":"<p>Alert</p> <pre><code>The Primary network is for PC and other VMs deployment, the Secondary network is requried in X-Ray lab\n</code></pre> <p>Open <code>https://POCxx-ABC Cluster IP:9440</code> (https://10.42.xx.xx:9440) in your browser and log in with the following credentials:</p> <ul> <li>Username - admin</li> <li> <p>Password - check password in table</p> </li> <li> <p>In the Prism Element UI click  &gt; Network Configuration &gt; Networks &gt; Create Network</p> </li> <li> <p>Fill out the following fields:</p> <ul> <li>Name - Primary</li> <li>Virtual Switch - vs0</li> <li>VLAN ID - 0</li> <li>Enable IP address management - leave it unselected</li> </ul> </li> <li> <p>Click Save</p> </li> <li> <p>Create the second network by clicking on + Create Network with     the following details:</p> <ul> <li>Name - Secondary</li> <li>Virtual Switch - vs0</li> <li>VLAN ID - HPOC Cluster ID 1 (e.g. for PHX-POC079,     VLAN ID would be 791)</li> <li>Enable IP address management - leave it unselected</li> </ul> </li> <li> <p>Click Save</p> </li> <li> <p>You should see two networks as shown here</p> <p></p> </li> </ul>"},{"location":"pcdeploy/pcdeploy/#prism-central-deploy","title":"Prism Central Deploy","text":"<ol> <li> <p>Navigate to Home page and click Register or create new in     Prism Central widget.</p> <p></p> </li> <li> <p>Choose the first Deploy option.</p> <p></p> </li> </ol>"},{"location":"pcdeploy/pcdeploy/#3-download-the-latest-version-and-click-deploy-1-vm-pc","title":"3.  Download the latest version and click Deploy 1-VM PC","text":"<ol> <li> <p>From the Desktop, download the latest version of Prism Central from the below path:</p> <ul> <li>\\nutanixdc.local\\dfs\\images\\Rahuman_Veritas\\PC\\PC2024.1.0.1</li> <li>use your VDI credntials to access the file that is shared in the share</li> <li>Reference: https://help.oe.nutanix.com/hpoc/en/articles/8336861-internal-using-the-hpoc-file-service</li> <li> </li> </ul> </li> <li> <p>Fill out the following fields:</p> <ul> <li>VM Name - PC</li> <li>Select A Container - SelfServiceContainer</li> <li>VM Sizing - SMALL - (UP TO 2500 VMs)</li> <li>NOTE: Please do not select Extra Small, this config will not allow you to enable Network Controller.</li> </ul> <p></p> </li> <li> <p>In Network config, fill our the following details (XX here is your POC number)</p> <ul> <li>AHV Network - Primary</li> <li>IP Address - 10.42.XX.XX (refer to table on IP to use)</li> <li>Subnet Mask - 255.255.255.128</li> <li>Default Gateway - 10.42.XX.1</li> <li>DNS Address(Es) - 10.42.194.10</li> </ul> <p></p> </li> <li> <p>Click Deploy</p> <p>Note</p> <p>The deployment will take about 30 mins, you can go to next lab sessions while waiting. After Prism Central VM is successfully deployed, open <code>https://*PC VM IP*:9440</code> (https://10.42.xx.xx:9440) in your browser and log in with the following credentials:</p> </li> <li> <p>When the deployment finishes, browse to your Prism Central IP     address (e.g. 10.42.XX.39) with the following details:</p> <ul> <li>Username - admin</li> <li>Password - default with capital N</li> <li>change password to ntnx/4DSTA</li> </ul> </li> <li> <p>Test if you can login Prism Central with the new password</p> </li> <li> <p>Accept EULA if displayed</p> </li> </ol>"},{"location":"pcdeploy/pcdeploy/#the-tar-file-will-need-to-be-added-to-the-cluster-manually","title":"The tar file will need to be added to the cluster manually","text":""},{"location":"pcdeploy/pcdeploy/#prism-central-registration","title":"Prism Central Registration","text":"<ol> <li> <p>Go back to POCxx-ABC Cluster (https://10.42.xx.xx:9440)</p> </li> <li> <p>Navigate to Home page and click cluster name POCxx-ABC and provide a cluster data service ip 10.42.xx.xx</p> <p></p> </li> <li> <p>Click Register or create new in Prism Central widget.</p> <p></p> </li> <li> <p>Choose the second Connect option.</p> <p></p> </li> <li> <p>Click Next</p> <p></p> </li> <li> <p>Fill out the following fields, leave others as default and click Connect:</p> <ul> <li>Prism Central IP - 10.42.xx.xx</li> <li>Port - 9440</li> <li>Username - admin</li> <li>Password - check password in RX</li> </ul> <p></p> <p>You will see an OK with PC's IP in Prism Central widget.</p> <p></p> </li> </ol> <p>You have successully registered Prism Element to be managed your Prism Central.</p> <ol> <li> <p>One you have completely registered, you can go into you Prism Central Management, enable Network Controller. This will enable VPC service for all cluster.</p> <p></p> </li> <li> <p>Login to the Prism Central, again.</p> </li> <li> <p>Click on Infrastructure in the App Switcher</p> </li> <li> <p>Scroll down on the side bar to go to Prism Central Settings</p> </li> <li> <p>Click on \"Network Controller\"</p> </li> <li> <p>Click on checkbox to enable Network Controller for VLAN Management as per screenshot below:</p> <p></p> <p></p> </li> <li> <p>You will see the service that has been enabled in the and completed in the cluster.</p> <p></p> </li> </ol>"},{"location":"taskman/taskman/","title":"Deploying Task Manager","text":"<p>The estimated time to complete this lab is 20 minutes.</p>"},{"location":"taskman/taskman/#overview","title":"Overview","text":"<p>This exercise walks you through importing and launching a Calm blueprint to deploy a simple Task Manager application used in Day2's Flow labs. You do not need to complete this exercise unless directed to do so as staging for another lab.</p>"},{"location":"taskman/taskman/#enabling-app-management","title":"Enabling App Management","text":"<p>Open https://&lt;Prism-Central-IP&gt;:9440/ in a browser and log in.</p> <p>From the navigation bar, select Service &gt; Calm</p> <p>Click Enable.</p> <p></p> <p>Select Enable App Management and click Save.</p> <p>::: note ::: title Note :::</p> <p>Nutanix Calm is a separately licensed product that can be used with Acropolis Starter, Pro, or Ultimate editions. Each Prism Central instance can manage up to 25 VMs for free before additional licensing is required. :::</p> <p></p> <p>You should get verification that Calm is enabling, which will take 5 to 10 minutes.</p> <p></p>"},{"location":"taskman/taskman/#creating-a-project","title":"Creating A Project","text":"<p>Projects are the logical construct that integrate Calm with Nutanix\\'s native Self-Service Portal (SSP) capabilities, allowing an administrator to assign both infrastructure resources and the roles/permissions of Active Directory users/groups to specific Blueprints and Applications.</p> <p>Click default in the project list</p> <p></p> <p>Under Infrastructure, fill out the following fields and click comfirm : - Select which resources you want this project to consume - Nutanix - AHV Cluster - \\&lt;POCxx-ABC&gt; - Under Network, select the Primary and if available, the Secondary networks.</p> <p>Select <code>star</code> for the Primary network to make it the default virtual network for VMs in the default project.</p> <p>Click Save.</p> <p></p>"},{"location":"taskman/taskman/#verifying-the-default-project","title":"Verifying the Default Project","text":"<p>In Prism Central, select Menu &gt; Services &gt; Calm.</p> <p></p> <p>Click  Projects in the left hand toolbar and select the default project.</p> <p>::: note ::: title Note :::</p> <p>Mousing over an icon will display its title. :::</p> <p>Under AHV Cluster verify your assigned cluster is selected from the drop-down list, otherwise select it.</p> <p>Under Network, verify the Primary and Secondary networks are selected and the Primary network is the default. Otherwise, make the selections as shown below.</p> <p></p> <p>If changes were made, click Save.</p>"},{"location":"taskman/taskman/#importing-the-blueprint","title":"Importing the Blueprint","text":"<p>Right-click on <code>this link &lt;TaskManager.json&gt;</code>{.interpreted-text role=\"download\"} and Save Link As... to download the blueprint for the example application used in this exercise.</p> <p>Click  Blueprints in the left hand toolbar to view available Calm blueprints.</p> <p>Click Upload Blueprint and select the TaskManager.json file previously downloaded.</p> <p>Fill out the following fields:</p> <ul> <li>Blueprint Name - Initials-TaskManager</li> <li>Project - default</li> </ul> <p></p> <p>Click Upload.</p> <p>::: note ::: title Note :::</p> <p>If you receive an error trying to upload the blueprint, refresh your browser and try again. :::</p>"},{"location":"taskman/taskman/#configuring-the-blueprint","title":"Configuring the Blueprint","text":"<p>Before you can launch the blueprint, you must first provide specify the information not stored in exported Calm blueprints, including credentials.</p> <p>In the Application Profile pane on the right, fill out the following field:</p> <ul> <li>Mysql_password - nutanix/4u</li> </ul> <p></p> <p>Select the WinClient service and in the pane on the right, under the VM tab, ensure the Image is set to the Windows10 disk image as shown below.</p> <p></p> <p>Under Network Adapters (NICs), ensure that NIC 1 is set to Primary as shown below.</p> <p></p> <p>Select the WebServer, HAProxy, and MySQL services and ensure each has NIC 1 set to Primary.</p> <p></p> <p>Click Save.</p> <p></p> <p>Click Credentials.</p> <p></p> <p>Expand the CENTOS credential by clicking its name. Copy and paste the following key into the SSH Private Key field:</p> <pre><code>-----BEGIN RSA PRIVATE KEY-----\nMIIEowIBAAKCAQEAii7qFDhVadLx5lULAG/ooCUTA/ATSmXbArs+GdHxbUWd/bNG\nZCXnaQ2L1mSVVGDxfTbSaTJ3En3tVlMtD2RjZPdhqWESCaoj2kXLYSiNDS9qz3SK\n6h822je/f9O9CzCTrw2XGhnDVwmNraUvO5wmQObCDthTXc72PcBOd6oa4ENsnuY9\nHtiETg29TZXgCYPFXipLBHSZYkBmGgccAeY9dq5ywiywBJLuoSovXkkRJk3cd7Gy\nhCRIwYzqfdgSmiAMYgJLrz/UuLxatPqXts2D8v1xqR9EPNZNzgd4QHK4of1lqsNR\nuz2SxkwqLcXSw0mGcAL8mIwVpzhPzwmENC5OrwIBJQKCAQB++q2WCkCmbtByyrAp\n6ktiukjTL6MGGGhjX/PgYA5IvINX1SvtU0NZnb7FAntiSz7GFrODQyFPQ0jL3bq0\nMrwzRDA6x+cPzMb/7RvBEIGdadfFjbAVaMqfAsul5SpBokKFLxU6lDb2CMdhS67c\n1K2Hv0qKLpHL0vAdEZQ2nFAMWETvVMzl0o1dQmyGzA0GTY8VYdCRsUbwNgvFMvBj\n8T/svzjpASDifa7IXlGaLrXfCH584zt7y+qjJ05O1G0NFslQ9n2wi7F93N8rHxgl\nJDE4OhfyaDyLL1UdBlBpjYPSUbX7D5NExLggWEVFEwx4JRaK6+aDdFDKbSBIidHf\nh45NAoGBANjANRKLBtcxmW4foK5ILTuFkOaowqj+2AIgT1ezCVpErHDFg0bkuvDk\nQVdsAJRX5//luSO30dI0OWWGjgmIUXD7iej0sjAPJjRAv8ai+MYyaLfkdqv1Oj5c\noDC3KjmSdXTuWSYNvarsW+Uf2v7zlZlWesTnpV6gkZH3tX86iuiZAoGBAKM0mKX0\nEjFkJH65Ym7gIED2CUyuFqq4WsCUD2RakpYZyIBKZGr8MRni3I4z6Hqm+rxVW6Dj\nuFGQe5GhgPvO23UG1Y6nm0VkYgZq81TraZc/oMzignSC95w7OsLaLn6qp32Fje1M\nEz2Yn0T3dDcu1twY8OoDuvWx5LFMJ3NoRJaHAoGBAJ4rZP+xj17DVElxBo0EPK7k\n7TKygDYhwDjnJSRSN0HfFg0agmQqXucjGuzEbyAkeN1Um9vLU+xrTHqEyIN/Jqxk\nhztKxzfTtBhK7M84p7M5iq+0jfMau8ykdOVHZAB/odHeXLrnbrr/gVQsAKw1NdDC\nkPCNXP/c9JrzB+c4juEVAoGBAJGPxmp/vTL4c5OebIxnCAKWP6VBUnyWliFhdYME\nrECvNkjoZ2ZWjKhijVw8Il+OAjlFNgwJXzP9Z0qJIAMuHa2QeUfhmFKlo4ku9LOF\n2rdUbNJpKD5m+IRsLX1az4W6zLwPVRHp56WjzFJEfGiRjzMBfOxkMSBSjbLjDm3Z\niUf7AoGBALjvtjapDwlEa5/CFvzOVGFq4L/OJTBEBGx/SA4HUc3TFTtlY2hvTDPZ\ndQr/JBzLBUjCOBVuUuH3uW7hGhW+DnlzrfbfJATaRR8Ht6VU651T+Gbrr8EqNpCP\ngmznERCNf9Kaxl/hlyV5dZBe/2LIK+/jLGNu9EJLoraaCBFshJKF\n-----END RSA PRIVATE KEY-----\n</code></pre> <p>Expand the WIN_VM_CRED credential by clicking its name. Enter nutanix/4u as the Password.</p> <p></p> <p>Click Save.</p> <p>Once the blueprint has been saved, click Back.</p> <p></p>"},{"location":"taskman/taskman/#launching-the-blueprint","title":"Launching the Blueprint","text":"<p>After the credentials have been provided, Publish, Download, and Launch are now available from the toolbar. Click Launch.</p> <p>Fill out the following fields:</p> <ul> <li>Name of the Application - Initials-TaskManager1</li> <li>User_initials - Initials</li> </ul> <p></p> <p>Click Create.</p> <p>You can monitor the status of your application deployment by clicking  Applications and clicking your application\\'s name.</p> <p>Provisioning the complete application will take approximately 15 minutes. Proceed to the next section of the lab while the application is provisioning.</p>"},{"location":"tools_vms/linux_tools_vm/","title":"Linux Tools VM","text":""},{"location":"tools_vms/linux_tools_vm/#overview","title":"Overview","text":"<p>This CentOS VM image will be staged with packages used to support multiple lab exercises.</p> <p>Deploy this VM on your assigned cluster if directed to do so as part of Lab Setup.</p> <p>Caution</p> <pre><code>Only deploy the VM once, it does not need to be cleaned up as part of any lab completion\n</code></pre>"},{"location":"tools_vms/linux_tools_vm/#deploying-centos","title":"Deploying CentOS","text":"<ol> <li> <p>In Prism Central &gt; select Menu&gt; Compute and Storage and VMs.</p> </li> <li> <p>Click on Create VM</p> </li> <li> <p>Fill out the following fields:</p> <ul> <li> <p>Name - Initials-Linux-ToolsVM</p> </li> <li> <p>Description - (Optional) Description for your VM.</p> </li> <li> <p>vCPU(s) - 2</p> </li> <li> <p>Number of Cores per vCPU - 1</p> </li> <li> <p>Memory - 4 GiB</p> </li> <li> <p>Select Attach Disk</p> <ul> <li>Type - DISK</li> <li>Operation - Clone from Image</li> <li>Image - CentOS7.qcow2</li> <li>Select Save</li> </ul> </li> </ul> </li> <li> <p>Select Attach to Subnet</p> <ul> <li>VLAN Name - Primary</li> <li>Select Save</li> </ul> </li> <li> <p>Click Next and Create VM to create the VM.</p> </li> <li> <p>In the list of VMs, select Initials-Linux-ToolsVM </p> </li> <li> <p>From the Actions menu, choose Power On.</p> </li> </ol>"},{"location":"tools_vms/linux_tools_vm/#installing-linux-tools","title":"Installing Linux Tools","text":"<ol> <li> <p>Login to the VM via ssh or Console session, using the following credentials:</p> </li> <li> <p>Install the software needed by running the following commands:</p> <pre><code>yum update -y\nyum install -y ntp ntpdate unzip stress nodejs python-pip s3cmd awscli\nyum install -y bind-utils nmap wget git\nnpm install -g request\nnpm install -g express\n</code></pre> </li> <li> <p>Enable and configure NTP by running the following commands:</p> <pre><code>systemctl start ntpd\nsystemctl enable ntpd\nntpdate -u -s 0.pool.ntp.org 1.pool.ntp.org 2.pool.ntp.org 3.pool.ntp.org\nsystemctl restart ntpd\n</code></pre> </li> <li> <p>Disable the firewall and SELinux by running the following commands:</p> <pre><code>systemctl disable firewalld\nsystemctl stop firewalld\nsetenforce 0\nsed -i 's/enforcing/disabled/g' /etc/selinux/config /etc/selinux/config\n</code></pre> </li> <li> <p>Optional step - Install Python by running the following commands:</p> <p><pre><code>yum -y install python36\npython3.6 -m ensurepip\nyum -y install python36-setuptools\npip install -U pip\npip install boto3\n</code></pre> Now your Linux Tools VM is ready for you to use.</p> </li> </ol>"},{"location":"tools_vms/windows_tools_vm/","title":"Overview","text":"<p>Deploy this Windows 10 VM on your assigned cluster if directed to do so as part of Lab Setup.</p> <pre><code>&lt;strong&gt;&lt;font color=\"red\"&gt;Only deploy the VM once, it does not need to be cleaned up as part of any lab completion.&lt;/font&gt;&lt;/strong&gt;\n</code></pre>"},{"location":"tools_vms/windows_tools_vm/#deploying-tools-vm","title":"Deploying Tools VM","text":"<p>Using an SSH client, connect to the Node A CVM IP \\&lt;10.42.xx.29&gt; in your assigned block using the following credentials:</p> <p>Username - nutanix</p> <p>Password - default</p> <p>Execute the following commands to upload AD image:</p> <pre><code>acli image.create Windows10 container=Images image_type=kDiskImage source_url=https://s3.amazonaws.com/get-ahv-images/Windows10-1709.qcow2\n</code></pre> <p>In Prism Central &gt; select <code>bars</code>{.interpreted-text role=\"fa\"} &gt; Virtual Infrastructure &gt; VMs, and click Create VM.</p> <p>Fill out the following fields:</p> <ul> <li> <p>Name - Initials-Windows-ToolsVM</p> </li> <li> <p>Description - (Optional) Description for your VM.</p> </li> <li> <p>vCPU(s) - 1</p> </li> <li> <p>Number of Cores per vCPU - 2</p> </li> <li> <p>Memory - 4 GiB</p> </li> <li> <p>Select + Add New Disk</p> <p>:   -   Type - DISK     -   Operation - Clone from Image Service     -   Image - Windows10-1709.qcow2     -   Select Add</p> </li> <li> <p>Select Add New NIC</p> <p>:   -   VLAN Name - Secondary     -   Select Add</p> </li> </ul> <p>Click Save to create the VM.</p> <p>Power On the VM.</p> <p>Login to the VM via RDP or Console session, using the following credentials:</p> <ul> <li>Username - NTNXLAB\\Administrator</li> <li>password - nutanix/4u</li> </ul>"},{"location":"xray/xray/","title":"Overview","text":"<p>Info</p> <p>Estimated time to complete: 60 Minutes</p> <p>X-Ray is an automated testing application for virtualized infrastructure solutions. It is capable of running test scenarios end-to-end to evaluate system attributes in real-world use cases. In this exercise you will deploy and configure an X-Ray VM, run X-Ray tests, and analyze results.</p> <p>As X-Ray powers down hosts for tests that evaluate availability and data ntegrity, it is best practice to run the X-Ray VM outside of the target cluster. Additionally, the X-Ray VM itself creates a small amount of storage and CPU overhead that could potentially skew results.</p> <p>In this lab, we will deploy X-Ray VM on POCxx-D, and evalutate cluster POCxx-ABC we just created.</p> <p>For environments where DHCP is unavailable (or there isn't a sufficiently large pool of addresses available), X-Ray supports Link-local or Zero Configuration networking, where the VMs communicate via self-assigned IPv4 addresses. In order to work, all of the VMs (including the X-Ray VM) need to reside on the same Layer 2 network. To use Link-local networking, your X-Ray VM's first NIC (eth0) should be on a network capable of communicating with your cluster. A second NIC (eth1) is added on a network without DHCP.</p>"},{"location":"xray/xray/#create-the-x-ray-vm-image","title":"Create the X-Ray VM image","text":"<ol> <li> <p>Open a terminal and SSH to Node-D CVM, enter CVM credentials and execute following commands</p> Logon to SSH console of CVM<pre><code>ssh -l nutanix 10.42.xx.32   #&lt;check password in RX&gt;\n</code></pre> </li> <li> <p>Upload the X-Ray Image</p> <pre><code>cvm:~$ acli image.create X-Ray container=Images image_type=kDiskImage source_url=http://10.42.194.11/images/Xray/4.1.3/xray-4.1.3.qcow2\n</code></pre> <p>Caution</p> <p>Wait until you see that the image upload is complete with a message <code>X-Ray: Complete</code></p> </li> <li> <p>You can confirm presence of X-Ray image by running the following command in the same shell</p> <p><pre><code>cvm:~$ acli image.list\n</code></pre> <pre><code># Output here\nImage name  Image type  Image UUID                            \nFoundation  kDiskImage  c970941a-d583-4640-8e03-9b2ca7336d00  \nX-Ray       kDiskImage  ac819fab-3fb9-4e85-99fd-97ca3f925ec8  &lt;&lt; here is your X-Ray Image\n</code></pre></p> </li> </ol>"},{"location":"xray/xray/#configuring-networks","title":"Configuring Networks","text":"<p>For targeting network, we will use the Secondary network VLAN for communication between the X-Ray VM and X-Ray worker VMs. This is accomplished via \"Zero Configuration\" networking, as the 3-node cluster Secondary and 1-node cluster Secondary networks are the same Layer 2 network and there is no DHCP.</p> <p>Now we switch to Prism portal of single node cluster D</p> <ol> <li>Open <code>https://&lt;POCxx-D Cluster IP&gt;:9440</code> (https://10.42.xx.32:9440) in your browser and log in with the following credentials:<ul> <li>Username - admin</li> <li>Password - check password in RX</li> </ul> </li> <li>Then, configue the Secondary network on the single node cluster D</li> <li>Click Create Network. Using the Cluster Details spreadsheet, fill out the following fields and click Save:<ul> <li>Name - Secondary</li> <li>Virtual Switch - vs0</li> <li>VLAN ID - HPOC Cluster ID 1 (e.g. for PHX-POC079, VLAN ID would be 791)</li> <li>Enable IP address management - leave it unselected</li> </ul> </li> <li>Click on Save</li> </ol>"},{"location":"xray/xray/#creating-x-ray-vm","title":"Creating X-Ray VM","text":"<ol> <li> <p>In Prism &gt; VM &gt; Table and click + Create VM.</p> </li> <li> <p>Fill out the following fields and click Save:</p> <ul> <li>Name - X-Ray</li> <li>vCPU(s) - 2</li> <li>Number of Cores per vCPU - 1</li> <li>Memory - 4 GiB</li> <li>Select + Add New Disk<ul> <li>Operation - Clone from Image Service</li> <li>Image - X-Ray</li> <li>Select Add</li> </ul> </li> <li>Select Add New NIC<ul> <li>VLAN Name - Primary</li> <li>Select Add</li> </ul> </li> <li>Select + Add New NIC<ul> <li>VLAN Name - Secondary</li> <li>Select Add</li> </ul> </li> </ul> </li> <li> <p>Select your X-Ray VM and click Power on.</p> <p>Info</p> <p>At the time of writing, X-Ray 4.1.3 is the latest available version. The URL for the latest X-Ray OVA &amp; QCOW2 images can be downloaded from the Nutanix Portal.</p> </li> <li> <p>Once the VM has started, click Launch Console</p> </li> <li> <p>Make sure the VM is booting to console</p> </li> <li> <p>Your X-Ray VM would have received an IP address from the DHCP server in Primary network</p> </li> <li> <p>Determine the IP address of the NIC (eth0) on the Primary network of the X-Ray VM from Prism Element and note it down</p> </li> </ol> <p>Note</p> <p>It is critical that you select the IP address of the network adapter assigned to the Primary network (you can confirm by comparing the MAC address in the VM console to the MAC address shown in Prism).</p>"},{"location":"xray/xray/#configuring-x-ray","title":"Configuring X-Ray","text":"<ol> <li> <p>Open <code>https://X-RAY-VM-IP</code> (E.g: https://10.42.xx.52) in a browser</p> <p>Caution</p> <pre><code>  Make sure to use the X-RAY-VM-IP that you noted down from the previous section\n</code></pre> </li> <li> <p>Click on Log in with Local Account</p> <p></p> </li> <li> <p>Click on Sign up now in the bottom of the screen</p> </li> <li> <p>Provide the following details</p> <ul> <li>Email - youremail@nutanix.com</li> <li>Password - set it to cluster password</li> </ul> </li> <li> <p>Click on Submit</p> </li> <li> <p>Select I have read and agree to the terms and conditions and click Accept.</p> <p></p> </li> <li> <p>Select Targets from the navigation bar and click Add Target. Fill out the following fields and click Next:</p> <ul> <li>Name - POCxx-ABC</li> <li>Manager Type - Prism</li> <li>Cluster Type - Nutanix</li> <li>Hypervisor - AHV</li> <li>Address - 3-Node Cluster Virtual IP 10.42.xx.37</li> <li>Username - admin</li> <li>Password - you 3 node cluster password</li> <li>Expiration Time - leave blank</li> </ul> <p></p> </li> <li> <p>Click Next</p> </li> <li> <p>Select Secondary under Network and click Next.</p> <p></p> </li> <li> <p>Click Next</p> </li> <li> <p>Under OOB Management Protocol, choose IPMI</p> </li> <li> <p>Review A, B and C node configurations</p> </li> <li> <p>From the drop down menu, choose Fill with Nutanix defaults</p> <p></p> </li> <li> <p>Click Next</p> </li> <li> <p>Click Run Validation.</p> <p></p> </li> <li> <p>Click Check Details to view validation progress.</p> <p></p> </li> <li> <p>Upon successful completion of validation, click Done.</p> <p></p> </li> </ol>"},{"location":"xray/xray/#running-x-ray-tests","title":"Running X-Ray Tests","text":"<p>While X-Ray offers many testing options, we will use Peak Performance Microbenchmark test in this lab.</p> <ol> <li> <p>Select Tests from the navigation bar</p> </li> <li> <p>In the list of tests, find Peak Performance Microbenchmark and click on View &amp; Run Test</p> <p></p> </li> <li> <p>Review the test description</p> </li> <li> <p>Enter the test name as Your Initials - Peak Perforamce Test</p> </li> <li> <p>Confirm your POCxx-ABC as the right target</p> </li> <li> <p>Choose the Default test variant</p> <p></p> </li> <li> <p>Click Run test.</p> <p>Caution</p> <pre><code>  X-Ray can run one test per target at a time. Many tests can be queued for a single target, allowing X-Ray to automatically run through multiple tests without requiring manual intervention. Through automation, X-Ray can drastically decrease the amount of time to conduct a POC.\n</code></pre> </li> <li> <p>Click on View Test</p> </li> <li> <p>You are able to monitor the test progress and results in the Results page</p> </li> <li> <p>Click on In Progress link to see which stage you are at in the test</p> <p></p> </li> <li> <p>You can see the random/sequential read/write tests are coming up soon</p> <p></p> </li> <li> <p>Click on Got it to return to the test Results page</p> </li> <li> <p>As the test runs you will be able to see the test results as shown here</p> <p>Note the minimum and maximum performance numbers all in one screen.</p> <p></p> </li> <li> <p>You are also able to get detailed view of the metrics as a Grafana dashboard, click on the Grafana Dashboard link</p> <p></p> </li> <li> <p>Grafana dashboards presents detailed metrics view</p> <p></p> </li> <li> <p>You are also able to generate reports (in PDF), export Test Results and re-run the tests.</p> <p></p> </li> </ol> <p>Tip</p> <p>The graphs are interactive, and you can click and drag to zoom into specific data/times on each individual graph. You can zoom out by clicking Reset Zoom.</p> <p>Each dotted blue line represents an event in the test, such as beginning a workload, powering off a node, etc. Clicking the blue dots will provide information about the event.</p> <p>Clicking the Actions drop down menu provides options to view the detailed log data, export the test results, and generate a PDF report.</p>"},{"location":"xray/xray/#working-with-x-ray-results","title":"Working with X-Ray Results","text":"<p>As X-Ray is using automation to perform the exact same tests and collect the same metrics on multiple systems/hypervisors, the results can be easily overlaid to compare solutions. In this exercise you will use X-Ray to compare BigData Ingestion test results between Nutanix and a competitor.</p> <p>The BigData Ingestion test compares the speed at which 1TB of sequential data can be written to a single VM on a cluster, as is common in workloads such as Splunk.</p> <ol> <li> <p>Download the following exported X-Ray test result:</p> <p>Competitor + Nutanix Big Data Ingest Results</p> </li> <li> <p>Select Results &gt; Import Test Result Bundle from the navigation bar.</p> </li> <li> <p>Click Choose File and select the Nutanix test results .zip file previously downloaded.</p> </li> <li> <p>Click Upload.</p> <p></p> </li> <li> <p>Once the file successfully uploads, you will see three results as shown here</p> <p></p> </li> <li> <p>Select all 3 BigData Ingestion results and click Create Comparison.</p> <p></p> </li> </ol> <p>The resulting charts show the combined metrics for all three solutions. You are able to see the software and hardware versions of the infrastructure cluster where the test was conducted.</p> <p>By hovering over the graph you can also see point-in-time performance metrics.</p> <p>In this case we can clearly see that the Nutanix solution is able to sustain a higher, and more consistent, rate of write throughput, resulting in a much faster time to complete ingesting the 1TB of data.</p> <p></p>"},{"location":"xray/xray/#exporting-x-ray-results","title":"Exporting X-Ray Results","text":"<ol> <li> <p>To export analysis results for use in proposal documents, etc., </p> </li> <li> <p>Select the results you need in All Resultspage and click on     Create report.</p> <p></p> <p>The results will open and can be printed or exported as PDF.</p> <p>Here is a results file for your reference.</p> <p>X-Ray Export Result PDF</p> </li> <li> <p>Multiple analyses can also be selected to generate a combined report     with the results from multiple tests, this can be extremely useful     for summarizing POC results.</p> <p>Question</p> <pre><code>   Can you explain **why** the Nutanix solution may produce better results than common HCI competitors?\n</code></pre> <p>Tip</p> <p>Check out the OpLog section of the Nutanix Bible</p> </li> </ol>"},{"location":"xray/xray/#takeaways","title":"Takeaways","text":"<ul> <li>X-Ray is a easy to use benchmarking tool to make your life in the field easier</li> <li>X-Ray has many testing scenarios (database, big data, etc) for specific use-cases</li> <li>X-Ray is available as a VM appliance as well as SaaS (tests can be run only on Nutanix HPOC clusters)</li> <li>X-Ray testing parameters can be customised easily to suit yours or your customer's testing requierements</li> </ul>"}]}